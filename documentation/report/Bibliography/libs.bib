Neural Networks

@article{Schmidhuber_2015,
  doi       = {10.1016/j.neunet.2014.09.003},
  url       = {https://doi.org/10.1016%2Fj.neunet.2014.09.003},
  year      = 2015,
  month     = {jan},
  publisher = {Elsevier {BV}
               },
  volume    = {61},
  pages     = {85--117},
  author    = {Jürgen Schmidhuber},
  title     = {Deep learning in neural networks: An overview},
  journal   = {Neural Networks}
}

@misc{zhang2019gradient,
  title         = {Gradient Descent based Optimization Algorithms for Deep Learning Models Training},
  author        = {Jiawei Zhang},
  year          = {2019},
  eprint        = {1903.03614},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{Sekhar,
  author  = {Sekhar, Ch and Meghana, P},
  year    = {2020},
  month   = {08},
  pages   = {21-28},
  title   = {A Study on Backpropagation in Artificial Neural Networks},
  volume  = {4},
  journal = {Asia-Pacific Journal of Neural Networks and Its Applications},
  doi     = {10.21742/AJNNIA.2020.4.1.03}
}

@misc{vaswani2017attention,
  title         = {Attention Is All You Need},
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year          = {2017},
  eprint        = {1706.03762},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}



CNN

@misc{oshea2015introduction,
  title         = {An Introduction to Convolutional Neural Networks},
  author        = {Keiron O'Shea and Ryan Nash},
  year          = {2015},
  eprint        = {1511.08458},
  archiveprefix = {arXiv},
  primaryclass  = {cs.NE}
}

@article{726791,
  author  = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal = {Proceedings of the IEEE},
  title   = {Gradient-based learning applied to document recognition},
  year    = {1998},
  volume  = {86},
  number  = {11},
  pages   = {2278-2324},
  doi     = {10.1109/5.726791}
}


SSL

@inproceedings{8903121,
  author    = {Chazan, Shlomo E. and Hammer, Hodaya and Hazan, Gershon and Goldberger, Jacob and Gannot, Sharon},
  booktitle = {2019 27th European Signal Processing Conference (EUSIPCO)},
  title     = {Multi-Microphone Speaker Separation based on Deep DOA Estimation},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {1-5},
  doi       = {10.23919/EUSIPCO.2019.8903121}
}

@inproceedings{Li_2016,
  doi       = {10.1109/iros.2016.7759437},
  url       = {https://doi.org/10.1109%2Firos.2016.7759437},
  year      = 2016,
  month     = {oct},
  publisher = {{IEEE}},
  author    = {Xiaofei Li and Laurent Girin and Fabien Badeig and Radu Horaud},
  title     = {Reverberant sound localization with a robot head based on direct-path relative transfer function},
  booktitle = {2016 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})}
}

@misc{amengual,
  author    = {Amengual Garamp},
  title     = {Spatial Analysis and auralization of room acoustics using a tetrahedral microphone},
  url       = {https://pubs.aip.org/asa/jasa/article/141/4/EL369/1059210/Spatial-analysis-and-auralization-of-room},
  journal   = {AIP Publishing},
  publisher = {AIP Publishing},
  author    = {Amengual Garamp;iacute;, Sebasti&amp;agrave; V. and Lachenmayr, Winfried and Mommertz, Eckard},
  year      = {2017},
  month     = {Apr}
} 

@inproceedings{Scola2010DirectionOA,
  title     = {Direction of arrival estimation : A two microphones approach},
  author    = {Carlos Fern{\'a}ndez Scola and Mar{\'i}a Dolores Bola{\~n}os Ortega},
  year      = {2010},
  booktitle = {2010 IEEE International Conference on Acoustics, Speech and Signal Processing}
}

@article{LIU201711,
  title    = {A survey of deep neural network architectures and their applications},
  journal  = {Neurocomputing},
  volume   = {234},
  pages    = {11-26},
  year     = {2017},
  issn     = {0925-2312},
  doi      = {https://doi.org/10.1016/j.neucom.2016.12.038},
  url      = {https://www.sciencedirect.com/science/article/pii/S0925231216315533},
  author   = {Weibo Liu and Zidong Wang and Xiaohui Liu and Nianyin Zeng and Yurong Liu and Fuad E. Alsaadi},
  keywords = {Autoencoder, Convolutional neural network, Deep learning, Deep belief network, Restricted Boltzmann machine},
  abstract = {Since the proposal of a fast learning algorithm for deep belief networks in 2006, the deep learning techniques have drawn ever-increasing research interests because of their inherent capability of overcoming the drawback of traditional algorithms dependent on hand-designed features. Deep learning approaches have also been found to be suitable for big data analysis with successful applications to computer vision, pattern recognition, speech recognition, natural language processing, and recommendation systems. In this paper, we discuss some widely-used deep learning architectures and their practical applications. An up-to-date overview is provided on four deep learning architectures, namely, autoencoder, convolutional neural network, deep belief network, and restricted Boltzmann machine. Different types of deep neural networks are surveyed and recent progresses are summarized. Applications of deep learning techniques on some selected areas (speech recognition, pattern recognition and computer vision) are highlighted. A list of future research topics are finally given with clear justifications.}
}

@article{Grumiaux_2022,
  doi       = {10.1121/10.0011809},
  url       = {https://doi.org/10.1121%2F10.0011809},
  year      = 2022,
  month     = {jul},
  publisher = {Acoustical Society of America ({ASA})},
  volume    = {152},
  number    = {1},
  pages     = {107--151},
  author    = {Pierre-Amaury Grumiaux and Sr{dj}an Kiti{{c}} and Laurent Girin and Alexandre Gu{{e}}rin},
  title     = {A survey of sound source localization with deep learning methods},
  journal   = {The Journal of the Acoustical Society of America}
}

@misc{grondin2018lightweight,
  title         = {Lightweight and Optimized Sound Source Localization and Tracking Methods for Open and Closed Microphone Array Configurations},
  author        = {Francois Grondin and Francois Michaud},
  year          = {2018},
  eprint        = {1812.00115},
  archiveprefix = {arXiv},
  primaryclass  = {eess.AS}
}

@misc{adavanne2019localization,
  title         = {Localization, Detection and Tracking of Multiple Moving Sound Sources with a Convolutional Recurrent Neural Network},
  author        = {Sharath Adavanne and Archontis Politis and Tuomas Virtanen},
  year          = {2019},
  eprint        = {1904.12769},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SD}
}

@misc{qian2020multiple,
  title         = {Multiple Sound Sources Localization from Coarse to Fine},
  author        = {Rui Qian and Di Hu and Heinrich Dinkel and Mengyue Wu and Ning Xu and Weiyao Lin},
  year          = {2020},
  eprint        = {2007.06355},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{chu2020learning,
  title         = {Learning Absolute Sound Source Localisation With Limited Supervisions},
  author        = {Yang Chu and Wayne Luk and Dan Goodman},
  year          = {2020},
  eprint        = {2001.10605},
  archiveprefix = {arXiv},
  primaryclass  = {cs.NE}
}

@article{article,
  author  = {Fan, Jing and Luo, Qian and Ma, Ding},
  year    = {2010},
  month   = {12},
  pages   = {312-317},
  title   = {Localization estimation of sound source by microphones array},
  volume  = {7},
  journal = {Procedia Engineering},
  doi     = {10.1016/j.proeng.2010.11.050}
}

SSDE

@misc{nihSoundSource,
  author       = {},
  title        = {{S}ound {S}ource {D}istance {E}stimation {U}sing {D}eep {L}earning: {A}n {I}mage {C}lassification {A}pproach --- ncbi.nlm.nih.gov},
  howpublished = {\url{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6982911/}},
  year         = {},
  note         = {[Accessed 03-Jul-2023]}
}

@article{article,
  author  = {Yiwere, M. and Rhee, E.J.},
  year    = {2017},
  month   = {01},
  pages   = {12384-12389},
  title   = {Distance estimation and localization of sound sources in reverberant conditions using deep neural networks},
  volume  = {12},
  journal = {International Journal of Applied Engineering Research}
}

@inproceedings{9551007,
  author    = {Zhagyparova, Kalamkas and Zhagypar, Ruslan and Zollanvari, Amin and Akhtar, Muhammad Tahir},
  booktitle = {2021 IEEE Region 10 Symposium (TENSYMP)},
  title     = {Supervised Learning-based Sound Source Distance Estimation Using Multivariate Features},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {1-5},
  doi       = {10.1109/TENSYMP52854.2021.9551007}
}

@misc{sobhdel2022fewshot,
  title         = {Few-Shot Sound Source Distance Estimation Using Relation Networks},
  author        = {Amirreza Sobhdel and Roozbeh Razavi-Far and Saeed Shahrivari},
  year          = {2022},
  eprint        = {2109.10561},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SD}
}

@article{s20010172,
  author         = {Yiwere, Mariam and Rhee, Eun Joo},
  title          = {Sound Source Distance Estimation Using Deep Learning: An Image Classification Approach},
  journal        = {Sensors},
  volume         = {20},
  year           = {2020},
  number         = {1},
  article-number = {172},
  url            = {https://www.mdpi.com/1424-8220/20/1/172},
  pubmedid       = {31892213},
  issn           = {1424-8220},
  abstract       = {This paper presents a sound source distance estimation (SSDE) method using a convolutional recurrent neural network (CRNN). We approach the sound source distance estimation task as an image classification problem, and we aim to classify a given audio signal into one of three predefined distance classes—one meter, two meters, and three meters—irrespective of its orientation angle. For the purpose of training, we create a dataset by recording audio signals at the three different distances and three angles in different rooms. The CRNN is trained using time-frequency representations of the audio signals. Specifically, we transform the audio signals into log-scaled mel spectrograms, allowing the convolutional layers to extract the appropriate features required for the classification. When trained and tested with combined datasets from all rooms, the proposed model exhibits high classification accuracies; however, training and testing the model in separate rooms results in lower accuracies, indicating that further study is required to improve the method’s generalization ability. Our experimental results demonstrate that it is possible to estimate sound source distances in known environments by classification using the log-scaled mel spectrogram.},
  doi            = {10.3390/s20010172}
}

Attacks

@article{yang2020patchattack,
  title   = {PatchAttack: A Black-box Texture-based Attack with Reinforcement Learning},
  author  = {Yang, Chenglin and Kortylewski, Adam and Xie, Cihang and Cao, Yinzhi and Yuille, Alan},
  journal = {arXiv preprint arXiv:2004.05682},
  year    = {2020}
}

@misc{takahashi2021adversarial,
  title         = {Adversarial attacks on audio source separation},
  author        = {Naoya Takahashi and Shota Inoue and Yuki Mitsufuji},
  year          = {2021},
  eprint        = {2010.03164},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SD}
}

@misc{alparslan2021adversarial,
  title         = {Adversarial Attacks against Neural Networks in Audio Domain: Exploiting Principal Components},
  author        = {Ken Alparslan and Yigit Alparslan and Matthew Burlick},
  year          = {2021},
  eprint        = {2007.07001},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{huang2017adversarial,
  title         = {Adversarial Attacks on Neural Network Policies},
  author        = {Sandy Huang and Nicolas Papernot and Ian Goodfellow and Yan Duan and Pieter Abbeel},
  year          = {2017},
  eprint        = {1702.02284},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{goodfellow2015explaining,
  title         = {Explaining and Harnessing Adversarial Examples},
  author        = {Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
  year          = {2015},
  eprint        = {1412.6572},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}

Classification

@inproceedings{5206848,
  author    = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
  title     = {ImageNet: A large-scale hierarchical image database},
  year      = {2009},
  volume    = {},
  number    = {},
  pages     = {248-255},
  doi       = {10.1109/CVPR.2009.5206848}
}

  @inproceedings{7952261,
  author    = {Gemmeke, Jort F. and Ellis, Daniel P. W. and Freedman, Dylan and Jansen, Aren and Lawrence, Wade and Moore, R. Channing and Plakal, Manoj and Ritter, Marvin},
  booktitle = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Audio Set: An ontology and human-labeled dataset for audio events},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {776-780},
  doi       = {10.1109/ICASSP.2017.7952261}
}

  Spectrogram/discrete fourier transform

  @book{MDFT07,
  author    = {Julius O. Smith},
  title     = {Mathematics of the Discrete Fourier Transform (DFT)},
  publisher = {W3K Publishing},
  address   = {\htmladdnormallink{http://www.w3k.org/books/}{http://www.w3k.org/books/}},
  year      = 2007,
  isbn      = { 978-0-9745607-4-8},
  url       = {https://ccrma.stanford.edu/~jos/mdft/}
}

  Inverse-spectrogram

  @inproceedings{6701851,
  author    = {Perraudin, Nathanaël and Balazs, Peter and Søndergaard, Peter L.},
  booktitle = {2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics},
  title     = {A fast Griffin-Lim algorithm},
  year      = {2013},
  volume    = {},
  number    = {},
  pages     = {1-4},
  doi       = {10.1109/WASPAA.2013.6701851}
}

Datasets

@inproceedings{Adavanne2019_DCASE,
  author    = {Adavanne, Sharath and Politis, Archontis and Virtanen, Tuomas},
  title     = {A Multi-room Reverberant Dataset for Sound Event Localization and Detection},
  booktitle = {Proceedings of the Detection and Classification of Acoustic Scenes and Events 2019 Workshop (DCASE2019)},
  address   = {New York University, NY, USA},
  month     = {October},
  year      = {2019},
  pages     = {10--14},
  abstract  = {This paper presents the sound event localization and detection (SELD) task setup for the DCASE 2019 challenge. The goal of the SELD task is to detect the temporal activities of a known set of sound event classes, and further localize them in space when active. As part of the challenge, a synthesized dataset where each sound event associated with a spatial coordinate represented using azimuth and elevation angles is provided. These sound events are spatialized using real-life impulse responses collected at multiple spatial coordinates in five different rooms with varying dimensions and material properties. A baseline SELD method employing a convolutional recurrent neural network is used to generate benchmark scores for this reverberant dataset. The benchmark scores are obtained using the recommended cross-validation setup.},
  url       = {https://dcase.community/workshop2019/proceedings}
}

@inproceedings{politis2020dataset,
    author = "Politis, Archontis and Adavanne, Sharath and Virtanen, Tuomas",
    title = "A Dataset of Reverberant Spatial Sound Scenes with Moving Sources for Sound Event Localization and Detection",
    booktitle = "Proceedings of the Detection and Classification of Acoustic Scenes and Events 2020 Workshop (DCASE2020)",
    address = "Tokyo, Japan",
    month = "November",
    year = "2020",
    pages = "165--169",
    abstract = "This report details the dataset and the evaluation setup of the Sound Event Localization \\& Detection (SELD) task for the DCASE 2020 Challenge. Training and testing SELD systems requires datasets of diverse sound events occurring under realistic acoustic conditions. A significantly more complex dataset is created for DCASE 2020 compared to the previous challenge. The two key differences are a more diverse range of acoustical conditions, and dynamic conditions, i.e. moving sources. The spatial sound scene recordings for all conditions are generated using real room impulse responses, while ambient noise recorded on location is added to the spatialized sound events. Additionally, an improved version of the SELD baseline used in the previous challenge is included, providing benchmark scores for the task.",
    url = "https://dcase.community/workshop2020/proceedings"
}
  

